{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxK2Tl5tDG3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from keras.utils import to_categorical\n",
        "import random\n",
        "import tensorflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Dense,Dropout,Embedding,LSTM\n",
        "from keras.layers import Dense, Activation,Flatten\n",
        "from keras.layers.convolutional import Conv1D,MaxPooling1D\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "#set random seed for the session and also for tensorflow that runs in background for keras\n",
        "# set_random_seed(123)\n",
        "tensorflow.random.set_seed(123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqZz6cduEnLI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b1648d7f-9048-4dca-b43a-41af71740bf2"
      },
      "source": [
        "train= pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/lab2/train.tsv\", sep=\"\\t\")\n",
        "test = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/lab2/test.tsv\", sep=\"\\t\")\n",
        "\n",
        "train.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS-ESrZeFkam",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7733c513-cfad-49c0-d0f3-a3fbaa3a87ba"
      },
      "source": [
        "train['Phrase'][100]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'would have a hard time sitting through this one .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "199hTmliFq7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_sentences(df):\n",
        "    reviews = []\n",
        "\n",
        "    for sent in tqdm(df['Phrase']):\n",
        "        \n",
        "        #remove html content\n",
        "        review_text = BeautifulSoup(sent).get_text()\n",
        "        \n",
        "        #remove non-alphabetic characters\n",
        "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
        "    \n",
        "        #tokenize the sentences\n",
        "        words = word_tokenize(review_text.lower())\n",
        "    \n",
        "        #lemmatize each word to its lemma\n",
        "        lemma_words = [lemmatizer.lemmatize(i) for i in words]\n",
        "    \n",
        "        reviews.append(lemma_words)\n",
        "\n",
        "    return(reviews)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gLyi7MoFt8k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "821d7368-6ecc-425e-ddcc-31880e9d76ba"
      },
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdnwbayRF3aG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "74b4ea88-bd25-4830-838b-b805b1c57288"
      },
      "source": [
        "#cleaned reviews for both train and test set retrieved\n",
        "train_sentences = clean_sentences(train)\n",
        "test_sentences = clean_sentences(test)\n",
        "print(len(train_sentences))\n",
        "print(len(test_sentences))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 156060/156060 [01:08<00:00, 2287.63it/s]\n",
            "100%|██████████| 66292/66292 [00:27<00:00, 2406.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "156060\n",
            "66292\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsY9a1UYGcPC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MK9IXO5F_iU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab0faf62-fb49-4a16-900f-1470a815417c"
      },
      "source": [
        "train_sentences[100]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['would', 'have', 'a', 'hard', 'time', 'sitting', 'through', 'this', 'one']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ6hi5jNGkfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target=train.Sentiment.values\n",
        "y_target=to_categorical(target)\n",
        "num_classes=y_target.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeiNPqjtGntp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "c4b78f46-9cd6-4182-b423-7f5322f63534"
      },
      "source": [
        "y_target"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-FBd_rcGrSb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_val,y_train,y_val=train_test_split(train_sentences,y_target,test_size=0.2,stratify=y_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Onx_a4NMGwmt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "2e7c7f5b-7219-4844-e56d-b8841af6fd76"
      },
      "source": [
        "#It is needed for initializing tokenizer of keras and subsequent padding\n",
        "\n",
        "unique_words = set()\n",
        "len_max = 0\n",
        "\n",
        "for sent in tqdm(X_train):\n",
        "    \n",
        "    unique_words.update(sent)\n",
        "    \n",
        "    if(len_max<len(sent)):\n",
        "        len_max = len(sent)\n",
        "        \n",
        "#length of the list of unique_words gives the no of unique words\n",
        "print(len(list(unique_words)))\n",
        "print(len_max)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 124848/124848 [00:00<00:00, 498283.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "13739\n",
            "48\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9u2VlJ8GzlW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "a0f76ec8-ab88-48bf-da27-465de8c54dbe"
      },
      "source": [
        "for x in tqdm(X_train[1:10]):\n",
        "  print(x)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:00<00:00, 7633.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['a', 'remarkable', 'movie', 'with', 'an', 'unsatisfying', 'ending', 'which', 'is', 'just', 'the', 'point']\n",
            "['emphasizing', 'the', 'disappointingly', 'generic', 'nature', 'of', 'the', 'entire', 'effort']\n",
            "['s', 'a', 'certain', 'robustness', 'to', 'this', 'engaging', 'mix', 'of', 'love', 'and', 'bloodletting']\n",
            "['of', 'lively', 'song', 'for', 'deft', 'punctuation']\n",
            "['it', 'minute']\n",
            "['too', 'impressed', 'with', 'it', 'own', 'solemn', 'insight']\n",
            "['confession', 'is', 'n', 't', 'always', 'coherent']\n",
            "['this', 'little', 'known', 'story', 'of', 'native', 'american', 'and']\n",
            "['evokes', 'the', 'th', 'century', 'with', 'a', 'subtlety', 'that', 'is', 'an', 'object', 'lesson', 'in', 'period', 'filmmaking']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02zAr2RdG6-j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0647e97f-6a7a-4866-d8fb-b9115e72267d"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=len(list(unique_words)))\n",
        "tokenizer.fit_on_texts(list(X_train))\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "X_test = tokenizer.texts_to_sequences(test_sentences)\n",
        "\n",
        "#padding done to equalize the lengths of all input reviews. LSTM networks needs all inputs to be same length.\n",
        "#Therefore reviews lesser than max length will be made equal using extra zeros at end. This is padding.\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=len_max)\n",
        "X_val = sequence.pad_sequences(X_val, maxlen=len_max)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=len_max)\n",
        "print(X_train.shape,X_val.shape,X_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(124848, 48) (31212, 48) (66292, 48)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmIPQxSZG_aB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "2b869763-90c2-40de-e7b2-642f2e221a9b"
      },
      "source": [
        "#Model using Keras CNN\n",
        "model=Sequential()\n",
        "model.add(Embedding(len(list(unique_words)),300,input_length=len_max))\n",
        "model.add(Conv1D(128,5,activation='relu'))\n",
        "model.add(MaxPooling1D(5))\n",
        "model.add(Conv1D(128,5,activation='relu'))\n",
        "#model.add(MaxPooling1D(35))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.005),metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 48, 300)           4121700   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 44, 128)           192128    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 8, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 4, 128)            82048     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               51300     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 4,447,681\n",
            "Trainable params: 4,447,681\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grFE9PgtHEma",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "d0ef130c-8d2b-411e-c0f0-4f3ba6f975d0"
      },
      "source": [
        "history=model.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=4, batch_size=256, verbose=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 124848 samples, validate on 31212 samples\n",
            "Epoch 1/4\n",
            "124848/124848 [==============================] - 210s 2ms/step - loss: 1.2095 - accuracy: 0.5346 - val_loss: 1.1472 - val_accuracy: 0.5600\n",
            "Epoch 2/4\n",
            "124848/124848 [==============================] - 208s 2ms/step - loss: 1.1099 - accuracy: 0.5800 - val_loss: 1.1204 - val_accuracy: 0.5691\n",
            "Epoch 3/4\n",
            "124848/124848 [==============================] - 205s 2ms/step - loss: 1.0680 - accuracy: 0.5956 - val_loss: 1.1117 - val_accuracy: 0.5769\n",
            "Epoch 4/4\n",
            "124848/124848 [==============================] - 206s 2ms/step - loss: 1.0428 - accuracy: 0.6038 - val_loss: 1.1171 - val_accuracy: 0.5780\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ0wnEwgHKlR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "0be90dc8-368c-409d-afab-a9ee4feb5d2d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create count of the number of epochs\n",
        "epoch_count = range(1, len(history.history['loss']) + 1)\n",
        "\n",
        "# Visualize learning curve. Here learning curve is not ideal. It should be much smoother as it decreases.\n",
        "#As mentioned before, altering different hyper parameters especially learning rate can have a positive impact\n",
        "#on accuracy and learning curve.\n",
        "plt.plot(epoch_count, history.history['loss'], 'r--')\n",
        "plt.plot(epoch_count, history.history['val_loss'], 'b-')\n",
        "plt.legend(['Training Loss', 'Validation Loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}