{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGH7hec6Hq0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from keras.utils import to_categorical\n",
        "import random\n",
        "import tensorflow \n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Dense,Dropout,Embedding,LSTM\n",
        "from keras.layers import Dense, Activation,Flatten\n",
        "from keras.layers.convolutional import Conv1D,MaxPooling1D\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "#set random seed for the session and also for tensorflow that runs in background for keras\n",
        "# set_random_seed(123)\n",
        "tensorflow.random.set_seed(123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXFN6zEqIM8b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3540cc60-d783-41a2-a031-623b503ecd78"
      },
      "source": [
        "train= pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/lab2/train.tsv\", sep=\"\\t\")\n",
        "test = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/lab2/test.tsv\", sep=\"\\t\")\n",
        "\n",
        "train.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FFQX_1eIRwU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51432787-9518-464e-d884-490cba88f05d"
      },
      "source": [
        "train['Phrase'][200]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "', Trouble Every Day is a plodding mess .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J0a6OKCLg1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_sentences(df):\n",
        "    reviews = []\n",
        "\n",
        "    for sent in tqdm(df['Phrase']):\n",
        "        \n",
        "        #remove html content\n",
        "        review_text = BeautifulSoup(sent).get_text()\n",
        "        \n",
        "        #remove non-alphabetic characters\n",
        "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
        "    \n",
        "        #tokenize the sentences\n",
        "        words = word_tokenize(review_text.lower())\n",
        "    \n",
        "        #lemmatize each word to its lemma\n",
        "        lemma_words = [lemmatizer.lemmatize(i) for i in words]\n",
        "    \n",
        "        reviews.append(lemma_words)\n",
        "\n",
        "    return(reviews)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkcHqQCZMq51",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ba5df0d7-b881-4cd2-f67f-5f94a5db2c6d"
      },
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdeW7jm0Mziz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "b1b80776-ab65-4c68-8e7d-688166f80829"
      },
      "source": [
        "#cleaned reviews for both train and test set retrieved\n",
        "train_sentences = clean_sentences(train)\n",
        "test_sentences = clean_sentences(test)\n",
        "print(len(train_sentences))\n",
        "print(len(test_sentences))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 156060/156060 [01:02<00:00, 2502.72it/s]\n",
            "100%|██████████| 66292/66292 [00:25<00:00, 2625.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "156060\n",
            "66292\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80YAvTdSNDEX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "007eeb54-7859-4e47-f193-738b1aac7dfb"
      },
      "source": [
        "train_sentences[100]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['would', 'have', 'a', 'hard', 'time', 'sitting', 'through', 'this', 'one']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEyemCsWN6dQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target=train.Sentiment.values\n",
        "y_target=to_categorical(target)\n",
        "num_classes=y_target.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI8dsOxON9kV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "98260514-ed43-4128-8151-c4a4283dbfe8"
      },
      "source": [
        "y_target"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s57S2URlOBZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_val,y_train,y_val=train_test_split(train_sentences,y_target,test_size=0.2,stratify=y_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx5-MKhvOFdH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c064f4b0-e48f-4123-ce8d-c402500f3377"
      },
      "source": [
        "#It is needed for initializing tokenizer of keras and subsequent padding\n",
        "\n",
        "unique_words = set()\n",
        "len_max = 0\n",
        "\n",
        "for sent in tqdm(X_train):\n",
        "    \n",
        "    unique_words.update(sent)\n",
        "    \n",
        "    if(len_max<len(sent)):\n",
        "        len_max = len(sent)\n",
        "        \n",
        "#length of the list of unique_words gives the no of unique words\n",
        "print(len(list(unique_words)))\n",
        "print(len_max)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 124848/124848 [00:00<00:00, 614142.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "13735\n",
            "48\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgR-RnsxOI_a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "c1ea27f3-a867-434e-e23b-a2a0f1745b90"
      },
      "source": [
        "for x in tqdm(X_train[1:10]):\n",
        "  print(x)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:00<00:00, 16673.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['the', 'year', 's', 'greatest', 'adventure']\n",
            "['on', 'that']\n",
            "['from', 'don', 'mullan', 's', 'script']\n",
            "['why', 'halftime', 'is', 'only', 'fifteen', 'minute', 'long']\n",
            "['what', 'begin', 'a', 'a', 'film', 'in', 'the', 'tradition', 'of', 'the', 'graduate', 'quickly', 'switch', 'into', 'something', 'more', 'recyclable', 'than', 'significant']\n",
            "['a', 'little', 'too', 'familiar', 'at', 'the', 'end']\n",
            "['subtlest', 'work']\n",
            "['the', 'movie', 'ended', 'so', 'damned', 'soon']\n",
            "['shaped', 'by', 'the', 'most', 'random', 'of', 'chance']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1fhNQ04ONta",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4966e29-9e5f-4bda-d773-c2f6991665a9"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=len(list(unique_words)))\n",
        "tokenizer.fit_on_texts(list(X_train))\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "X_test = tokenizer.texts_to_sequences(test_sentences)\n",
        "\n",
        "#padding done to equalize the lengths of all input reviews. LSTM networks needs all inputs to be same length.\n",
        "#Therefore reviews lesser than max length will be made equal using extra zeros at end. This is padding.\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=len_max)\n",
        "X_val = sequence.pad_sequences(X_val, maxlen=len_max)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=len_max)\n",
        "print(X_train.shape,X_val.shape,X_test.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(124848, 48) (31212, 48) (66292, 48)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awR8NzdBORZD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "c52c232c-f948-4b0c-adf7-b4aa750441f9"
      },
      "source": [
        "early_stopping = EarlyStopping(min_delta = 0.001, mode = 'max', monitor='val_acc', patience = 2)\n",
        "callback = [early_stopping]\n",
        "\n",
        "#Model using Keras LSTM\n",
        "model=Sequential()\n",
        "model.add(Embedding(len(list(unique_words)),300,input_length=len_max))\n",
        "model.add(LSTM(128,dropout=0.5, recurrent_dropout=0.5,return_sequences=True))\n",
        "model.add(LSTM(64,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.005),metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 48, 300)           4120500   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 48, 128)           219648    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               6500      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 4,396,561\n",
            "Trainable params: 4,396,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjxBC6veOf3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67432c64-7525-4d7a-ffc9-f62c96fdd04d"
      },
      "source": [
        "!rm -R ./logs/ # rf"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove './logs/': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20-x8GBAOlv0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "88e65d4e-4200-47b0-945f-a4f416306620"
      },
      "source": [
        "history=model.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=4, batch_size=256, verbose=1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 124848 samples, validate on 31212 samples\n",
            "Epoch 1/4\n",
            "124848/124848 [==============================] - 373s 3ms/step - loss: 1.0174 - accuracy: 0.5912 - val_loss: 0.8526 - val_accuracy: 0.6487\n",
            "Epoch 2/4\n",
            "124848/124848 [==============================] - 376s 3ms/step - loss: 0.8218 - accuracy: 0.6633 - val_loss: 0.8138 - val_accuracy: 0.6619\n",
            "Epoch 3/4\n",
            "124848/124848 [==============================] - 378s 3ms/step - loss: 0.7586 - accuracy: 0.6868 - val_loss: 0.8110 - val_accuracy: 0.6706\n",
            "Epoch 4/4\n",
            "124848/124848 [==============================] - 377s 3ms/step - loss: 0.7186 - accuracy: 0.7004 - val_loss: 0.8054 - val_accuracy: 0.6701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0detx2xCOqpl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "49a6cd2d-dbe1-440c-d198-e025de887e96"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create count of the number of epochs\n",
        "epoch_count = range(1, len(history.history['loss']) + 1)\n",
        "\n",
        "# Visualize learning curve. Here learning curve is not ideal. It should be much smoother as it decreases.\n",
        "#As mentioned before, altering different hyper parameters especially learning rate can have a positive impact\n",
        "#on accuracy and learning curve.\n",
        "plt.plot(epoch_count, history.history['loss'], 'r--')\n",
        "plt.plot(epoch_count, history.history['val_loss'], 'b-')\n",
        "plt.legend(['Training Loss', 'Validation Loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}